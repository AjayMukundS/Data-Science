{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node[ ' group ' ]\n",
    "    #print(left[0][len(left[0])-1])\n",
    "    #print(right[0][len(right[0])-1])\n",
    "    del(node[ ' group ' ])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node[ ' left ' ] = node[ ' right ' ] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node[ ' left ' ], node[ ' right ' ] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node[ ' left ' ] = to_terminal(left)\n",
    "    #elif purity(left):\n",
    "    #    x= 10\n",
    "    else:\n",
    "        node[ ' left ' ] = get_split(left)\n",
    "        if(node[ ' left ' ]!= 0):\n",
    "            split(node[ ' left ' ], max_depth, min_size, depth+1)\n",
    "        #else:\n",
    "        #    node[ ' left ' ]= { ' index ' : 0, ' value ' :left[0][len(left[0])-1], ' group ' :0}\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node[ ' right ' ] = to_terminal(right)\n",
    "    else:\n",
    "        node[ ' right ' ] = get_split(right)\n",
    "        if(node[ ' right ' ]!= 0):\n",
    "            split(node[ ' right ' ], max_depth, min_size, depth+1)\n",
    "        #else:\n",
    "        #    node[ ' right ' ]= { ' index ' : 0, ' value ' :right[0][len(right[0])-1], ' group ' :0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    data= pd.DataFrame(dataset)\n",
    "    minBC = 9999\n",
    "    index= 0\n",
    "    for col_num in range(len(data.columns)-1):\n",
    "        cols = [col_num, len(data.columns)-1]\n",
    "        var = data[cols]\n",
    "        New_data= pd.DataFrame(var)\n",
    "        categories = list(New_data[cols[0]].unique())\n",
    "        classes = list(var[cols[1]].unique())\n",
    "        if(len(classes)== 1):\n",
    "            return 0;\n",
    "        count_matrix ={}\n",
    "        for cl in classes:\n",
    "            count_dict = {}\n",
    "            for ct in categories:\n",
    "                cell = var[(var[cols[0]] == ct) & (var[cols[1]] == cl)]\n",
    "                count_dict[ct] = cell.shape[0]\n",
    "            count_matrix[cl] = count_dict\n",
    "        class_distribution_matrix = pd.DataFrame(count_matrix)\n",
    "        if(class_distribution_matrix.shape[0]!= 1):\n",
    "            class_distribution_array= class_distribution_matrix.iloc[:, :class_distribution_matrix.shape[1]].values\n",
    "            N= data.shape[0]\n",
    "            NV= len(categories)\n",
    "            CA= N/NV\n",
    "            EP= 0\n",
    "            for variable in range(NV):\n",
    "                sum= 0\n",
    "                for num in range(class_distribution_matrix.shape[1]):\n",
    "                    sum= sum+ class_distribution_array[variable][num]\n",
    "                result= CA- sum\n",
    "                if(result< 0):\n",
    "                    result= result* -1\n",
    "                EP= EP+result\n",
    "            #At this particular point, we got EP (Equal Split Parameter)\n",
    "            covariance_matrix= class_distribution_matrix.cov()\n",
    "            eig_vals, eig_vecs = LA.eig(covariance_matrix)\n",
    "            \n",
    "            sum= 0\n",
    "            for value in range(len(eig_vals)):\n",
    "                sum= sum+ eig_vals[value]\n",
    "            average= sum/len(eig_vals)\n",
    "            \n",
    "            BC= EP/average\n",
    "            print(BC)\n",
    "            if(BC< minBC):\n",
    "                minBC= BC\n",
    "                index= col_num\n",
    "                matrix= class_distribution_matrix\n",
    "    print(minBC)\n",
    "    print(index)\n",
    "    print(matrix)\n",
    "    if matrix.shape[0]== 2:\n",
    "        value= matrix.index.values[0]\n",
    "        #print('value= ', value)\n",
    "    #else:\n",
    "        #find impurity\n",
    "        \n",
    "    value= dataset[0][index]\n",
    "    group= test_split(index, value, dataset)\n",
    "    return { ' index ' :index, ' value ' :value, ' group ' :group}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(dataset)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    #print(node)\n",
    "    #if node[ ' group ' ]== 0:\n",
    "    #    print('['+node['value']+']')\n",
    "    #    return 0\n",
    "    if isinstance(node, dict):\n",
    "        print( ' %s[Var0%d == %s] ' % ((depth* ' ' , (node[ ' index ' ]+1), node[ ' value ' ])))\n",
    "        print_tree(node[ ' left ' ], depth+1)\n",
    "            \n",
    "        print_tree(node[ ' right ' ], depth+1)\n",
    "    else:\n",
    "        print( ' %s[%s] ' % ((depth* ' ' , node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2857142857142865\n",
      "1.9999999999999998\n",
      "0.23529411764705882\n",
      "0.23529411764705882\n",
      "2\n",
      "             1  2\n",
      "Round        5  1\n",
      "Rectangular  0  4\n",
      "1.4999999999999998\n",
      "4.8\n",
      "1.4999999999999998\n",
      "0\n",
      "       1  2\n",
      "White  3  0\n",
      "Black  2  0\n",
      "Pink   0  1\n",
      " [Var03 == Round] \n",
      "  [0] \n",
      "  [Var01 == White] \n",
      "   [1] \n",
      "   [1] \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Sample Dataset.csv')\n",
    "dataset= data.iloc[:, :4].values\n",
    "tree = build_tree(dataset,2, 1)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
